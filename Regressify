#!/usr/bin/python3
#Bismillahir_rahmanir_rahim
#LunarLumos
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import argparse
import re
import csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, SGDRegressor, HuberRegressor, PassiveAggressiveRegressor
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score
import warnings
warnings.filterwarnings("ignore")

RED = "\033[91m"
GREEN = "\033[92m"
YELLOW = "\033[93m"
BLUE = "\033[94m"
MAGENTA = "\033[95m"
CYAN = "\033[96m"
BOLD = "\033[1m"
RESET = "\033[0m"
BLINK = "\033[5m"

def print_banner():
    print(f"""{BOLD}{YELLOW}  
  _____                                    
  (, /   )                         ,  /)    
    /__ /  _  _   __   _  _   _      //     
 ) /   \\__(/_(_/_/ (__(/_/_)_/_)__(_/(_ (_/_
(_/         .-/                    /)  .-/  
           (_/                    (/  (_/    
{RESET}""")
    print(f"{BLINK}{MAGENTA}                                   LunarLumos{RESET}\n")

def load_dataset(file_path):
    """Load dataset from CSV, Excel, Parquet, or JSON."""
    if file_path.endswith('.csv'):
        # Detect the delimiter using csv.Sniffer
        with open(file_path, 'r', newline='', encoding='utf-8') as f:
            sample = f.read(1024)  # Read a small portion of the file
            delimiter = csv.Sniffer().sniff(sample).delimiter
        
        return pd.read_csv(file_path, sep=delimiter)  # Use the detected delimiter
    elif file_path.endswith(('.xls', '.xlsx')):
        return pd.read_excel(file_path)
    elif file_path.endswith('.parquet'):
        return pd.read_parquet(file_path)
    elif file_path.endswith('.json'):
        return pd.read_json(file_path)
    else:
        print(f"{RED}‚ùå Unsupported file format!{RESET}")
        exit(1)

def clean_target_column(y):
    """Convert target values to numeric, handling cases with units or symbols."""
    def convert(value):
        value = str(value)
        value = re.sub(r'[^\d.]', '', value) 
        return float(value) if value else np.nan
    return y.apply(convert).dropna()

def suggest_best_regression_model(dataset_path):
    print_banner()
    
    # Load dataset
    df = load_dataset(dataset_path)
    df.dropna(inplace=True)

    if df.empty:
        print(f"{RED}‚ùå The dataset is empty after removing missing values!{RESET}")
        exit(1)

    # Limit dataset to 10 features if needed
    if df.shape[1] > 10:
        df = df.iloc[:, :10]

    target_column = df.columns[-1]
    X = df.iloc[:, :-1]
    y = df.iloc[:, -1]

    if X.empty:
        print(f"{RED}‚ùå Feature set is empty after data cleaning!{RESET}")
        exit(1)

    # Convert categorical columns to numerical
    X = pd.get_dummies(X, drop_first=True)
    
    y = clean_target_column(y)

    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    models = {
        "Linear Regression": LinearRegression(),
        "Ridge Regression": Ridge(alpha=1.0),
        "Lasso Regression": Lasso(alpha=0.1),
        "ElasticNet Regression": ElasticNet(alpha=0.1, l1_ratio=0.5),
        "Bayesian Ridge Regression": BayesianRidge(),
        "SGD Regression": SGDRegressor(),
        "Huber Regression": HuberRegressor(),
        "Passive Aggressive Regression": PassiveAggressiveRegressor(),
        "Polynomial Regression (Degree 2)": PolynomialFeatures(degree=2),
        "Support Vector Regression (SVR)": SVR(kernel='rbf'),
        "Decision Tree Regression": DecisionTreeRegressor(),
        "Random Forest Regression": RandomForestRegressor(n_estimators=100),
        "Gradient Boosting Regression": GradientBoostingRegressor(),
        "AdaBoost Regression": AdaBoostRegressor(n_estimators=100),
        "Extra Trees Regression": ExtraTreesRegressor(n_estimators=100),
        "Hist Gradient Boosting Regression": HistGradientBoostingRegressor(),
        "K-Nearest Neighbors Regression": KNeighborsRegressor(n_neighbors=5),
        "Neural Network Regression": MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500)
    }

    results = {}

    for name, model in models.items():
        if name == "Polynomial Regression (Degree 2)":
            poly = PolynomialFeatures(degree=2)
            X_poly = poly.fit_transform(X_train)
            model = LinearRegression()
            model.fit(X_poly, y_train)
            X_test_poly = poly.transform(X_test)
            y_pred = model.predict(X_test_poly)
        elif name == "Support Vector Regression (SVR)":
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
        else:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        evs = explained_variance_score(y_test, y_pred)

        results[name] = {"MSE": mse, "R2 Score": r2, "MAE": mae, "Explained Variance Score": evs}
    results_df = pd.DataFrame(results).T.sort_values(by="R2 Score", ascending=False)


    print(f"\n{BOLD}{YELLOW}üìä Regression Model Performance:{RESET}")
    print(results_df)
    # Best model
    best_model = results_df.index[0]
    best_metrics = results_df.loc[best_model]

    print(f"\n{BOLD}{GREEN}üöÄ Suggested Best Model: {best_model}{RESET}")
    print(f"üîπ {BOLD}R¬≤ Score:{RESET} {best_metrics['R2 Score']:.4f}")
    print(f"üîπ {BOLD}Mean Squared Error:{RESET} {best_metrics['MSE']:.2e}")
    print(f"üîπ {BOLD}Mean Absolute Error:{RESET} {best_metrics['MAE']:.2e}")
    print(f"üîπ {BOLD}Explained Variance Score:{RESET} {best_metrics['Explained Variance Score']:.4f}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Automatically suggest the best ML regression model for a given dataset.")
    parser.add_argument("-d", "--dataset", required=True, help="Path to the dataset file")
    args = parser.parse_args()
    suggest_best_regression_model(args.dataset)
